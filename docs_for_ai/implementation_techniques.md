# Thonnyãƒ—ãƒ©ã‚°ã‚¤ãƒ³å®Ÿè£…ã«å¿…è¦ãªè¦ç´ æŠ€è¡“

## 1. ã‚¨ãƒ‡ã‚£ã‚¿ã®æ“ä½œã¨ãƒ­ãƒƒã‚¯æ©Ÿèƒ½

### ã‚¨ãƒ‡ã‚£ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•
```python
from thonny import get_workbench

# ç¾åœ¨ã®ã‚¨ãƒ‡ã‚£ã‚¿ã‚’å–å¾—
workbench = get_workbench()
editor = workbench.get_editor_notebook().get_current_editor()
if editor:
    text_widget = editor.get_text_widget()  # tkinter Textã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
```

### ã‚¨ãƒ‡ã‚£ã‚¿ã®ãƒ­ãƒƒã‚¯/ã‚¢ãƒ³ãƒ­ãƒƒã‚¯
```python
# ã‚¨ãƒ‡ã‚£ã‚¿ã‚’ãƒ­ãƒƒã‚¯ï¼ˆç·¨é›†ã‚’ç¦æ­¢ï¼‰
text_widget.config(state=tk.DISABLED)  # ã¾ãŸã¯ state="disabled"

# ã‚¨ãƒ‡ã‚£ã‚¿ã‚’ã‚¢ãƒ³ãƒ­ãƒƒã‚¯ï¼ˆç·¨é›†ã‚’è¨±å¯ï¼‰
text_widget.config(state=tk.NORMAL)    # ã¾ãŸã¯ state="normal"
```

### ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰æ›¸ãæ›ãˆ
```python
# ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä¸€æ™‚çš„ã«ã‚¢ãƒ³ãƒ­ãƒƒã‚¯
text_widget.config(state=tk.NORMAL)

# ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—
current_content = text_widget.get("1.0", tk.END)

# ãƒ†ã‚­ã‚¹ãƒˆã®æŒ¿å…¥
text_widget.insert("1.0", "# AI generated code\n")  # å…ˆé ­ã«æŒ¿å…¥
text_widget.insert(tk.END, "\n# End of code")       # æœ«å°¾ã«è¿½åŠ 

# ãƒ†ã‚­ã‚¹ãƒˆã®å‰Šé™¤ã¨ç½®æ›
text_widget.delete("1.0", tk.END)  # å…¨å‰Šé™¤
text_widget.insert("1.0", new_content)  # æ–°ã—ã„å†…å®¹ã‚’æŒ¿å…¥

# å†åº¦ãƒ­ãƒƒã‚¯
text_widget.config(state=tk.DISABLED)
```

## 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®å®Ÿè£…

### é¸æŠãƒ†ã‚­ã‚¹ãƒˆã®æ¤œå‡º
```python
def _has_selection(widget):
    """Textã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆãŒãƒ†ã‚­ã‚¹ãƒˆé¸æŠã‚’æŒã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    if not isinstance(widget, tk.Text):
        return False
    try:
        return bool(widget.tag_ranges("sel"))
    except:
        return False
```

### é¸æŠãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—
```python
if widget.tag_ranges("sel"):
    selected_text = widget.get(tk.SEL_FIRST, tk.SEL_LAST)
```

### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®è¿½åŠ æ–¹æ³•

#### æ–¹æ³•1: ç‹¬è‡ªã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼
```python
from tkinter import Menu

# ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ä½œæˆ
context_menu = Menu(text_widget, tearoff=0)
context_menu.add_command(label="ã‚³ãƒ¼ãƒ‰è§£èª¬", command=explain_handler)

# å³ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒã‚¤ãƒ³ãƒ‰
if sys.platform == "darwin":  # macOS
    text_widget.bind("<Button-2>", show_context_menu, add='+')
    text_widget.bind("<Control-Button-1>", show_context_menu, add='+')
else:  # Windows/Linux
    text_widget.bind("<Button-3>", show_context_menu, add='+')

def show_context_menu(event):
    context_menu.tk_popup(event.x_root, event.y_root)
```

#### æ–¹æ³•2: Thonnyã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«çµ±åˆ
```python
workbench.add_command(
    command_id="explain_selection",
    menu_name="edit",
    command_label="ã‚³ãƒ¼ãƒ‰è§£èª¬ (AI)",
    handler=explain_handler,
    group=80  # ãƒ¡ãƒ‹ãƒ¥ãƒ¼å†…ã®ä½ç½®
)
```

#### æ–¹æ³•3: ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒãƒ³ã‚°ï¼ˆé«˜åº¦ï¼‰
```python
# æ—¢å­˜ã®ShellMenuã‚¯ãƒ©ã‚¹ã‚’æ‹¡å¼µ
import thonny.shell

OriginalShellMenu = thonny.shell.ShellMenu

class CustomShellMenu(OriginalShellMenu):
    def add_extra_items(self):
        super().add_extra_items()
        self.add_separator()
        self.add_command(
            label="ğŸ¤–ã‚³ãƒ¼ãƒ‰è§£èª¬",
            command=self.explain_selection
        )

# ãƒ‘ãƒƒãƒã‚’é©ç”¨
thonny.shell.ShellMenu = CustomShellMenu
```

## 3. ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æ§‹é€ ã®åŸºæœ¬

### å¿…é ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
thonnycontrib/
â””â”€â”€ plugin_name/
    â””â”€â”€ __init__.py  # load_plugin()é–¢æ•°ãŒå¿…é ˆ
```

### load_plugin()ã®å®Ÿè£…
```python
def load_plugin():
    """ThonnyãŒå‘¼ã³å‡ºã™ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    from thonny import get_workbench
    
    try:
        workbench = get_workbench()
        
        # ãƒ“ãƒ¥ãƒ¼ã‚’ç™»éŒ²
        from .views import AssistantView
        workbench.add_view(
            AssistantView,
            "AI Assistant",
            "se",  # ä½ç½®: south-east
            view_id="AIAssistantView"
        )
        
        # ã‚³ãƒãƒ³ãƒ‰ã‚’ç™»éŒ²
        workbench.add_command(
            command_id="show_ai_assistant",
            menu_name="tools",
            command_label="AI Assistant",
            handler=show_assistant_handler
        )
        
    except Exception as e:
        import logging
        logging.error(f"Failed to load plugin: {e}")
```

## 4. éåŒæœŸå‡¦ç†ã¨ã‚¹ãƒ¬ãƒƒãƒ‡ã‚£ãƒ³ã‚°

### ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã®éåŒæœŸåŒ–
```python
import threading
import queue

class LLMClient:
    def __init__(self):
        self.model = None
        self.model_loaded = False
        self.loading_queue = queue.Queue()
    
    def load_model_async(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        thread = threading.Thread(target=self._load_model)
        thread.daemon = True
        thread.start()
    
    def _load_model(self):
        try:
            from llama_cpp import Llama
            self.model = Llama(
                model_path="path/to/model.gguf",
                n_ctx=4096,
                n_gpu_layers=0  # CPU only
            )
            self.model_loaded = True
            self.loading_queue.put(("success", None))
        except Exception as e:
            self.loading_queue.put(("error", str(e)))
```

### UIæ›´æ–°ã®éåŒæœŸå‡¦ç†
```python
def update_ui_from_thread():
    """ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰UIã‚’å®‰å…¨ã«æ›´æ–°"""
    workbench.get_root().after(0, lambda: ui_update_function())
```

## 5. è¨­å®šç®¡ç†

### Thonnyã®è¨­å®šã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
```python
from thonny import get_workbench

# è¨­å®šã‚’ä¿å­˜
workbench = get_workbench()
workbench.set_option("thonny_local_ollama.model_path", "/path/to/model.gguf")
workbench.set_option("thonny_local_ollama.skill_level", "beginner")

# è¨­å®šã‚’èª­ã¿è¾¼ã¿
model_path = workbench.get_option("thonny_local_ollama.model_path", default="")
skill_level = workbench.get_option("thonny_local_ollama.skill_level", default="beginner")
```

### ã‚«ã‚¹ã‚¿ãƒ JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
```python
import json
import os
from pathlib import Path

class Config:
    def __init__(self):
        self.config_path = Path.home() / ".thonny_local_ollama" / "config.json"
        self.load()
    
    def load(self):
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                self.data = json.load(f)
        else:
            self.data = self.get_defaults()
    
    def save(self):
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_path, 'w') as f:
            json.dump(self.data, f, indent=2)
```

## 6. UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å®Ÿè£…

### åŸºæœ¬çš„ãªãƒ“ãƒ¥ãƒ¼ã‚¯ãƒ©ã‚¹
```python
import tkinter as tk
from tkinter import ttk
from tkinter.scrolledtext import ScrolledText

class AssistantView(ttk.Frame):
    def __init__(self, master):
        super().__init__(master)
        self.init_ui()
    
    def init_ui(self):
        # ãƒãƒ£ãƒƒãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.chat_display = ScrolledText(self, wrap=tk.WORD)
        self.chat_display.pack(fill=tk.BOTH, expand=True)
        
        # å…¥åŠ›ã‚¨ãƒªã‚¢
        self.input_frame = ttk.Frame(self)
        self.input_frame.pack(fill=tk.X)
        
        self.input_text = tk.Text(self.input_frame, height=3)
        self.input_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        self.send_button = ttk.Button(
            self.input_frame,
            text="é€ä¿¡",
            command=self.send_message
        )
        self.send_button.pack(side=tk.RIGHT)
```

## 7. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã®å®Ÿè£…

```python
import queue
import threading

class StreamingHandler:
    def __init__(self, display_widget):
        self.display_widget = display_widget
        self.response_queue = queue.Queue()
        self.streaming = False
    
    def stream_response(self, prompt):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚’é–‹å§‹"""
        self.streaming = True
        thread = threading.Thread(
            target=self._generate_stream,
            args=(prompt,)
        )
        thread.daemon = True
        thread.start()
        
        # UIã‚’å®šæœŸçš„ã«æ›´æ–°
        self._update_display()
    
    def _generate_stream(self, prompt):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆ"""
        for token in self.model.generate_tokens(prompt):
            if not self.streaming:
                break
            self.response_queue.put(token)
        self.response_queue.put(None)  # çµ‚äº†ã‚·ã‚°ãƒŠãƒ«
    
    def _update_display(self):
        """ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¦UIã‚’æ›´æ–°"""
        try:
            while True:
                token = self.response_queue.get_nowait()
                if token is None:
                    self.streaming = False
                    break
                self.display_widget.insert(tk.END, token)
        except queue.Empty:
            pass
        
        if self.streaming:
            self.display_widget.after(50, self._update_display)
```

## 8. ã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ­ã‚®ãƒ³ã‚°

```python
import logging

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# Thonnyã®ãƒ­ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆ
from thonny import get_workbench
workbench = get_workbench()
# ãƒ­ã‚°ã¯System Shellã¨thonny.logã«å‡ºåŠ›ã•ã‚Œã‚‹

# ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®ä¾‹
try:
    # å±é™ºãªæ“ä½œ
    result = risky_operation()
except Exception as e:
    logger.error(f"Operation failed: {e}", exc_info=True)
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®é€šçŸ¥
    from tkinter import messagebox
    messagebox.showerror(
        "ã‚¨ãƒ©ãƒ¼",
        f"æ“ä½œãŒå¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
    )
```

## 9. ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ

```python
import sys
import platform

def get_platform_specific_path():
    if sys.platform == "win32":
        return Path.home() / "AppData" / "Local" / "thonny_local_ollama"
    elif sys.platform == "darwin":
        return Path.home() / "Library" / "Application Support" / "thonny_local_ollama"
    else:  # Linux
        return Path.home() / ".config" / "thonny_local_ollama"

# ãƒã‚¦ã‚¹ãƒœã‚¿ãƒ³ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œ
def bind_context_menu(widget):
    if platform.system() == "Darwin":  # macOS
        widget.bind("<Button-2>", show_menu)
        widget.bind("<Control-Button-1>", show_menu)
    else:  # Windows/Linux
        widget.bind("<Button-3>", show_menu)
```

## 10. é…å»¶èª­ã¿è¾¼ã¿ï¼ˆLazy Loadingï¼‰ã®å®Ÿè£…

```python
class LLMClient:
    def __init__(self):
        self._model = None
        self._loading = False
        self._load_lock = threading.Lock()
    
    @property
    def model(self):
        """ãƒ¢ãƒ‡ãƒ«ã¸ã®æœ€åˆã®ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«èª­ã¿è¾¼ã‚€"""
        if self._model is None and not self._loading:
            with self._load_lock:
                if self._model is None and not self._loading:
                    self._loading = True
                    self._load_model()
        return self._model
    
    def _load_model(self):
        """å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å‡¦ç†"""
        try:
            from llama_cpp import Llama
            self._model = Llama(
                model_path=self.get_model_path(),
                n_ctx=4096
            )
        finally:
            self._loading = False
```

ã“ã‚Œã‚‰ã®è¦ç´ æŠ€è¡“ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€Thonnyç”¨ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’å®Ÿè£…ã§ãã¾ã™ã€‚